{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "598dbac6-cea5-47fd-87b9-8b94376b5065",
   "metadata": {},
   "source": [
    "# 13_dramv_functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed30f767-0458-462b-9b76-f123a8a7c8e3",
   "metadata": {},
   "source": [
    "This notebook creates and tests functions for summarizing metabolic potential of viral genes identified by DRAM-v."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133b8cbe-80c3-481b-95d8-6d6e5d1f4e10",
   "metadata": {},
   "source": [
    "## Load Packages and example data for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7e08b4-02f3-49a7-8c46-7a10d40bd56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "import glob\n",
    "import os # these two packages are good for searching and navigating file systems\n",
    "import os.path as op\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "ex_file_path = '/Users/melissaherring/Google Drive/My Drive/MH_project/dramv/cv1_AM-654-B02/annotations.tsv' # create file path\n",
    "columns_to_keep = ['Unnamed: 0', 'rank', 'kegg_hit', 'viral_hit', 'pfam_hits', 'vogdb_hits'] # make a list of columns to look at\n",
    "df = pd.read_csv(ex_file_path, sep = \"\\t\")[columns_to_keep] # read the file and store only the columns from the list as a variable named df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70deead5-349f-4ba1-a6a7-39841b8b9938",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd768a6-733a-4897-8b11-3dc784319478",
   "metadata": {},
   "source": [
    "## Function 1: get_ann_text\n",
    "\n",
    "This function formats the text from the following columns: 'viral_hit', 'kegg_hit', 'pfam_hits', 'vogdb_hits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d45dc7-026c-42ea-8ca6-39adb436a22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ann_text(hit_text, column_type = 'viral_hit'): # column_type = 'viral_hit' sets the default column_type as 'viral_hit'; \n",
    "                                                        # if column_type isn't specified, then the function assumes it is 'viral_hit'\n",
    "    '''\n",
    "    args:\n",
    "        hit_text: text string from DRAMv for 'viral_hit' column\n",
    "    returns:\n",
    "        text string of just annotation information, not organism or hit id\n",
    "    \n",
    "    exe_input: YP_004325053.1 hypothetical protein PSSM7_226 [Prochlorococcus phage P-SSM7]\n",
    "    exe_output: hypothetical protein PSSM7_226\n",
    "    '''\n",
    "    \n",
    "    if type(hit_text) == float: # if the text belongs to the float type, return that text; float = NA in these data\n",
    "        return hit_text\n",
    "    \n",
    "    if column_type == 'viral_hit': # if the column_type is 'viral_hit',\n",
    "        no_org = hit_text.split(\"[\")[0] # split the text by brackets ('[') and return the first part of the resulting text\n",
    "        no_acc_id = \" \".join(no_org.split(\" \")[1:-1]) # join the resulting text from the line above with a space, \n",
    "                                                        # then split by a space and return the second part of the text without the 2nd to last character\n",
    "        return no_acc_id\n",
    "    \n",
    "    if column_type in ['kegg_hit']: # if the column_type is 'kegg_hit',\n",
    "        no_ee = hit_text.split(\"[\")[0].strip() # split the text by brackets and return the first part of the resulting text; strip () removes trailing \n",
    "                                                    # space\n",
    "        return no_ee\n",
    "    \n",
    "    if column_type == 'pfam_hits': # if the column_type is 'pfam_hits',\n",
    "        no_pf_ids = \";\".join([text.split(\"[\")[0].strip() for text in hit_text.split(\";\")]) # split the text by brackets and return the first part of the\n",
    "                                    # resulting text without the trailing space then split by a semicolon (;) \n",
    "                                    # and return all pfam annotations joined using a semicolon (there are multiple annotations in this one column)\n",
    "        return no_pf_ids\n",
    "    \n",
    "    if column_type == 'vogdb_hits': # if the column_type is 'vogdb_hits',\n",
    "        no_code = hit_text.split(\";\")[0] # split the text by a semicolon and return the first part of the resulting text\n",
    "        no_acc = \" \".join(no_code.split(\" \")[1:]) # split the text from the line above with a space and return the second part of the text joined by a \n",
    "                                                    # space\n",
    "        return no_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c681c73a-cd92-4fa4-a208-321c5cbd8e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_ann_text test using cv1_AM-654-B02\n",
    "\n",
    "df['viral_ann_text'] = df['viral_hit'].apply(get_ann_text, args = ('viral_hit',)) # create a new column that is the result of applying the get_ann_text \n",
    "                                                                        # function to the 'viral_hit' column using column_type = 'viral_hit'\n",
    "df['kegg_ann_text'] = df['kegg_hit'].apply(get_ann_text, args = ('kegg_hit',)) # create a new column that is the result of applying the get_ann_text\n",
    "                                                                        # function to the 'kegg_hit' column using column_type = 'kegg_hit'\n",
    "df['pfam_ann_text'] = df['pfam_hits'].apply(get_ann_text, args = ('pfam_hits',)) # create a new column that is the result of applying the get_ann_text \n",
    "                                                                        # function to the 'pfam_hits' column using column_type = 'pfam_hits'\n",
    "df['vogdb_ann_text'] = df['vogdb_hits'].apply(get_ann_text, args = ('vogdb_hits',))# create a new column that is the result of applying the get_ann_text \n",
    "                                                                        # function to the 'vogdb_hit' column using column_type = 'vogdb_hits'\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45adfe0b-bc18-4812-8f9f-dc48a6b2eead",
   "metadata": {},
   "source": [
    "## Function 2: grab_annotation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31f0fdf-86d5-434f-a0c1-c6a84ebcc33d",
   "metadata": {},
   "source": [
    "This function looks at the viral_hit, kegg_hit, pfam_hits, and vogdb_hits columns and decides which annotation to keep moving forward (to avoid overlap when looking at only one column at a time)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b85d60-7f15-4ef9-8e0f-eab17ffc1696",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_annotation(line):\n",
    "    col_preference = ['kegg_hit', 'pfam_hits', 'viral_hit', 'vogdb_hits'] # create a list of columns to iterate through\n",
    "\n",
    "    for col in col_preference: # for each column in the col_preference list,\n",
    "        if type(line[col]) != str: # if the observation is not a string, continue\n",
    "            continue\n",
    "        elif 'hypothetical' not in line[col]: # if the observation is not hypothetical,\n",
    "            keep_text = get_ann_text(line[col], column_type = col) # apply the get_ann_function using the column_type of the observation \n",
    "                                                                    # and store the result in a variable called keep_text\n",
    "            keep_source = col # and store the observation's column_type in a variable called keep_source\n",
    "            return keep_text, keep_source\n",
    "        else: # otherwise continue\n",
    "            continue\n",
    "            \n",
    "    for col in col_preference: # for each column in the col_preference list,\n",
    "        if type(line[col]) != str: # if the observation is not a string, continue\n",
    "            continue\n",
    "        else: # if the observation is a string,\n",
    "            keep_text = get_ann_text(line[col], column_type = col) # apply the get_ann_text function to the observation using the column_type \n",
    "                                                                    # of the observation and store the result in a variable called keep_text\n",
    "            keep_source = col # store the observation's column_type in a variable called keep_source\n",
    "            return keep_text, keep_source\n",
    "    \n",
    "    return math.nan, math.nan # return NAs as NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7379719f-b139-4cfc-b975-832f231a0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grab_annotation test using cv1_AM-654-B02\n",
    "\n",
    "df[['annotation','annotation_source']] = df.apply(grab_annotation, axis=1, result_type='expand') # create two new columns that are the result of applying\n",
    "                                                                                            # the grab_annotation function\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc88b5b-c2cf-49a5-b6e2-211f9387784e",
   "metadata": {},
   "source": [
    "## Function 3: assign_annot\n",
    "\n",
    "This function is an alternative to function 2 (grab_annotation). Based on the dramv ranks, this function chooses the best data base annotation column to keep for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b07f25-a5d0-4bcb-9c62-77273dd8f9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if rank = A, grab kegg_hit\n",
    "# if rank = B, grab viral_hit\n",
    "# if rank = C, grab don't grab pfam_hits\n",
    "# if rank = D, grab pfam_hits\n",
    "# if rank = E, don't grab kegg_hit, viral_hit, or pfam_hits\n",
    "\n",
    "def assign_annot(line):\n",
    "        \n",
    "        annot_source = math.nan\n",
    "        \n",
    "        if line['rank'] == 'A' :\n",
    "            annot_source = 'kegg_hit'\n",
    "        \n",
    "        elif line['rank'] == 'B' :\n",
    "            annot_source = 'viral_hit'\n",
    "        \n",
    "        elif line['rank'] == 'C' and type(line['kegg_hit']) == str :\n",
    "            annot_source = 'kegg_hit'\n",
    "        \n",
    "        elif line['rank'] == 'C' and not pd.isna(line['kegg_hit']) and type(line['viral_hit']) == str :\n",
    "            annot_source = 'viral_hit'\n",
    "        \n",
    "        elif line['rank'] == 'C' and pd.isna(line['kegg_hit']) and type(line['viral_hit']) == str :\n",
    "            annot_source = 'vogdb_hits'\n",
    "\n",
    "        elif line['rank'] == 'D' :\n",
    "            annot_source = 'pfam_hits'\n",
    "        \n",
    "        elif line['rank'] == 'E' and not pd.isna(line['vogdb_hits']) and type(line['vogdb_hits']) == str :\n",
    "            annot_source = 'vogdb_hits'\n",
    "                                            \n",
    "        elif line['rank'] == 'E' and pd.isna(line['vogdb_hits']) and type(line['vogdb_hits']) == str :\n",
    "            annot_source = np.na\n",
    "            \n",
    "        else:\n",
    "            return math.nan, math.nan\n",
    "        \n",
    "        keep_annot = get_ann_text(line[annot_source], column_type = annot_source)\n",
    "        return keep_annot, annot_source\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13868d9-b81d-4172-b36a-93b5f82e29b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['annotation','annotation_source']] = df.apply(assign_annot, axis=1, result_type='expand')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed58ec5-bb84-4771-8d5d-e7311b22cd77",
   "metadata": {},
   "source": [
    "## 4: For loop for trimming dramv annotation output files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b821af89-d40c-4ee2-96c4-936ae4df6ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop to trim to include only columns I want to keep, create missing columns with NAs\n",
    "\n",
    "tsv_pattern = \"/Users/melissaherring/Google Drive/My Drive/MH_project/dramv/*/annotations.tsv\"  # Replace with your file pattern\n",
    "tsv_file_paths = glob.glob(tsv_pattern)\n",
    "columns_to_keep = ['Unnamed: 0', 'rank', 'kegg_hit', 'viral_hit', 'pfam_hits', 'vogdb_hits']\n",
    "num_columns_list = []\n",
    "\n",
    "\n",
    "for file_path in tsv_file_paths:\n",
    "    df = pd.read_csv(file_path, delimiter='\\t')\n",
    "    if 'kegg_hit' not in df.columns:\n",
    "        df.insert(loc=len(df.columns), column='kegg_hit', value=pd.NA)\n",
    "    if 'viral_hit' not in df.columns:\n",
    "        df.insert(loc=len(df.columns), column='viral_hit', value=pd.NA)\n",
    "    if 'pfam_hits' not in df.columns:\n",
    "        df.insert(loc=len(df.columns), column='pfam_hits', value=pd.NA)\n",
    "    if 'vogdb_hits' not in df.columns:\n",
    "        df.insert(loc=len(df.columns), column='vogdb_hits', value=pd.NA)\n",
    "    \n",
    "    df_name = df.iloc[0, 1]\n",
    "    \n",
    "    dir_path = '/Users/melissaherring/Google Drive/My Drive/MH_project/dramv_trim/'\n",
    "    file_name = f\"{df_name}.csv\"\n",
    "    full_path = dir_path + file_name\n",
    "    df[columns_to_keep].to_csv(full_path, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f72d5b-2d39-4535-ba42-6e7d3e82b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop for the number of columns in each annotations.tsv file\n",
    "\n",
    "tsv_pattern = \"/Users/melissaherring/Google Drive/My Drive/MH_project/dramv_trim/*.csv\"\n",
    "tsv_file_paths = glob.glob(tsv_pattern)\n",
    "\n",
    "# Create a list to store the number of columns for each file\n",
    "num_columns_list = []\n",
    "\n",
    "# Loop through the list of file paths and count the columns in each TSV file\n",
    "for file_path in tsv_file_paths:\n",
    "    df = pd.read_csv(file_path)\n",
    "    num_columns = df.shape[1]\n",
    "    num_columns_list.append(num_columns)\n",
    "\n",
    "# Create a DataFrame with file paths and the number of columns\n",
    "result_df = pd.DataFrame({'File': tsv_file_paths, 'Number of Columns': num_columns_list})\n",
    "#result_df.to_csv('num_cols.csv')\n",
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf05efd-87ec-41c9-91d9-8f29c7045781",
   "metadata": {},
   "source": [
    "## 5: For loop to apply all functions on trimmed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21331ae2-488d-4680-a957-6f6c7e874361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for loop for applying functions\n",
    "\n",
    "tbl['viral_ann_text'] = tbl['viral_hit'].apply(get_ann_text, args = ('viral_hit',))\n",
    "    tbl['kegg_ann_text'] = tbl['kegg_hit'].apply(get_ann_text, args = ('kegg_hit',)) \n",
    "    tbl['pfam_ann_text'] = tbl['pfam_hits'].apply(get_ann_text, args = ('pfam_hits',)) \n",
    "    tbl['vogdb_ann_text'] = tbl['vogdb_hits'].apply(get_ann_text, args = ('vogdb_hits',))\n",
    "    \n",
    "    tbl[['annotation','annotation_source']] = tbl.apply(assign_annot, axis=1, result_type='expand')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
